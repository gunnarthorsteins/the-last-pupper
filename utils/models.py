"""
Utility function for generating convolutional autoencoder models.

Alex Angus

4/23/21
"""
# import tensorflow modules
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, Dropout, Conv2DTranspose, UpSampling2D
from tensorflow.keras import layers, losses
from tensorflow.keras import Model
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.losses import categorical_crossentropy


def build_autoencoder(optimizer='adam', loss='mse', metrics=['mse'],
                      input_shape=(256, 256, 3), summary=True,
                      interpolation='bilinear'):
    """
    Generate a convolutional autoencoder using the general architecture
    described here (https://arxiv.org/abs/1711.08763) with tensorflow Sequential API.

    params:
        optimizer: string indicating optimizer type
        loss: string indicating loss type
        metrics: list of strings indicating evaluation metrics to be used
        input_shape: tuple indicating input shape (pixel width, pixel height, channels)
        summary: boolean print model summary upon generation
        interpolation: string indicating upsampling inference type ('bilinear' or 'nearest')

    returns:
        autoencoder: tensorflow autoencoder model
    """
    autoencoder = Sequential()                                                  # initialize ae
    autoencoder.add(Conv2D(filters=10, kernel_size=(5, 5), strides=(1,1),       # add first convolutional layer
                           activation='relu', input_shape=input_shape,
                           padding='same', name='Conv2D_1'))

    autoencoder.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2),              # add first MaxPooling layer
                                 padding='valid', name='MaxPool_1'))

    autoencoder.add(Conv2D(filters=20, kernel_size=(5, 5), strides=(1,1),       # add second convolutional layer
                           activation='relu', padding='same', name='Conv2D_2'))

    autoencoder.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2),              # add second MaxPooling layer
                                 padding='valid', name='MaxPool_2'))

    autoencoder.add(UpSampling2D(interpolation=interpolation,                   # add first unpooling layer
                                 name='UpSample_1'))

    autoencoder.add(Conv2DTranspose(filters=20, kernel_size=(5, 5),             # add first deconvolutional layer
                                    strides=(1, 1), activation='relu',
                                    padding='same', name='Conv2DTrans_1'))

    autoencoder.add(UpSampling2D(interpolation=interpolation,                   # add second unpooling layer
                                 name='UpSample_2'))

    autoencoder.add(Conv2DTranspose(filters=10, kernel_size=(5, 5),             # add second deconvolutional layer
                                    strides=(1, 1), activation='relu',
                                    padding='same', name='Conv2DTrans_2'))

    autoencoder.add(Conv2DTranspose(filters=3, kernel_size=(1, 1),              # add reconstruction layer
                                    strides=(1, 1), activation='relu',
                                    name='Conv2DTrans_Reconstruction'))
    if summary:                                                                 # generate model summary
        autoencoder.summary()

    autoencoder.compile(optimizer=optimizer, loss=loss, metrics=metrics)        # compile model

    return autoencoder


def build_cae(autoencoder, optimizer='adam',
              loss='sparse_categorical_crossentropy', metrics=['accuracy'],
              output_size=3, summary=True, dropout=None):
    """
    Generate a convolutional autoencoder classifier using the general architecture
    described here (https://arxiv.org/abs/1711.08763) with tensorflow Sequential API.

    params:
        autoencoder: autoencoding model generated by build_autoencoder()
        optimizer: string indicating optimizer type
        loss: string indicating loss type
        metrics: list of strings indicating evaluation metrics to be used
        output_size: int indicating the number of classes
        summary: boolean print model summary upon generation
        dropout: float specifying dropout rate (None = no dropout)

    returns:
        cae: tensorflow convolutional autoencoder classifier model
    """
    encoder = Model(inputs=autoencoder.input,                                   # take encoding portion of autoencoder
                    outputs=autoencoder.layers[-6].output,
                    name='encoder')

    for encoding_layer in encoder.layers:                                       # freeze encoding weights
        encoding_layer.trainable = False

    input_shape = (encoder.output.shape[1],                                     # define input shape of classifier portion as output of encoder
                   encoder.output.shape[2],
                   encoder.output.shape[3])

    classifier = Sequential(name='classifier')                                  # initialize classifier model

    classifier.add(tf.keras.layers.Input(shape=input_shape,                     # add input layer to classifier
                                         name='dense_input'))

    if dropout is not None: # NOTE: I think dropout should be applied to the input image, not the latent representation.
        classifier.add(tf.keras.layers.SpatialDropout2D(dropout))               # apply dropout

    classifier.add(Flatten(name='flatten'))                                     # flatten input

    classifier.add(Dense(400, activation='relu', name='dense_1'))               # add first fully connected layer

    classifier.add(Dense(200, activation='relu', name='dense_2'))               # add second fully connected layer

    classifier.add(Dense(output_size, activation='softmax', name='softmax'))    # add softmax layer

    cae = Model(inputs=encoder.inputs, outputs=classifier(encoder.output),      # combine encoder and classifier
                name='cae')

    if summary:                                                                 # generate model summary
        cae.summary()
        classifier.summary()

    cae.compile(optimizer=optimizer, loss=loss, metrics=metrics)                # compile model

    return cae


class accuracy_callback(tf.keras.callbacks.Callback):
    """
    Early stopping callback. Training is stopped to avoid overfitting when
    validation accuracy reaches 80%.
    """
    def on_epoch_end(self, epoch, logs={}):                                     # define on_epoch_end(). This function is called after every epoch.
        if(logs.get('val_accuracy') >= 0.8):                                    # if validation accuracy exceeds 80%
            print("\nReached %2.2f%% accuracy, training done." %(80))
            self.model.stop_training = True                                     # stop training
